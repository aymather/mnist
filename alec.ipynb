{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16a486c70>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0], cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: (28, 28)\n",
      "Output Shape: (784,)\n",
      "Min Value: 0.0\n",
      "Max Value: 1.0\n"
     ]
    }
   ],
   "source": [
    "image = x_train[0]\n",
    "input_shape = np.shape(image)\n",
    "output_shape = np.shape(image.flatten())\n",
    "min_val = np.min(image)\n",
    "max_val = np.max(image)\n",
    "\n",
    "print(f'Input Shape: ' + str(input_shape))\n",
    "print(f'Output Shape: ' + str(output_shape))\n",
    "print(f'Min Value: ' + str(min_val))\n",
    "print(f'Max Value: ' + str(max_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Dense Model\n",
    "\n",
    "### Stats\n",
    "- Loss: 0.06887\n",
    "- Acc: 98.31%\n",
    "\n",
    "### Model\n",
    "- Optimizer: Adam\n",
    "- Loss: SparseCategoricalCrossentropy\n",
    "\n",
    "1. Dense, 256 neurons, 20% dropout, relu\n",
    "2. Dense, 256 neurons, 20% dropout, relu\n",
    "3. Dense, 10 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept = 'best'\n",
    "neurons = [256]\n",
    "layers = [2]\n",
    "dropout = [0.2]\n",
    "\n",
    "for num_neurons in neurons:\n",
    "    for num_layers in layers:\n",
    "        for num_dropout in dropout:\n",
    "\n",
    "            # Sequential model\n",
    "            model = tf.keras.models.Sequential()\n",
    "\n",
    "            # Start by flattening inputs\n",
    "            model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "            \n",
    "            # Add dense layers\n",
    "            for l in range(num_layers):\n",
    "                model.add(tf.keras.layers.Dense(num_neurons, activation='relu'))\n",
    "                model.add(tf.keras.layers.Dropout(num_dropout))\n",
    "\n",
    "            # Always add a final dense layer with 10 neurons for classification\n",
    "            model.add(tf.keras.layers.Dense(10))\n",
    "\n",
    "            # Tensorboard\n",
    "            log_fullfile = f'./tensorboard_logs/concept:{concept}-neurons:{num_neurons}-layers:{num_layers}-dropout:{num_dropout}-{time.time()}'\n",
    "            tensorboard_callback = TensorBoard(log_dir=log_fullfile)\n",
    "\n",
    "            # Compile model\n",
    "            model.compile(\n",
    "                optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy']\n",
    "            )\n",
    "\n",
    "            # Train\n",
    "            model.fit(\n",
    "                x_train,\n",
    "                y_train,\n",
    "                epochs=10,\n",
    "                validation_data=(x_test, y_test),\n",
    "                callbacks=[tensorboard_callback]\n",
    "            )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Conv Model\n",
    "\n",
    "### Stats\n",
    "- Loss: 0.02161\n",
    "- Acc: 99.42%\n",
    "\n",
    "### Model\n",
    "- Optimizer: Adam\n",
    "- Loss: SparseCategoricalCrossentropy\n",
    "- Augmentations:\n",
    "    - rotation_range: 10\n",
    "    - zoom_range: 0.1\n",
    "    - width_shift_range: 0.1\n",
    "    - height_shift_range: 0.1\n",
    "\n",
    "1. Conv2D:32:3x3:relu\n",
    "2. Max:2x2\n",
    "3. Dropout:0.2\n",
    "4. Conv2D:64:3x3:relu\n",
    "5. Max:2x2\n",
    "6. Dropout:0.2\n",
    "7. Flatten\n",
    "8. Dense:64:relu\n",
    "9. Dense:10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we're using convolutional layers now, we need to do an extra step of preprocessing\n",
    "# All we're doing here is adding a dimension at the lowest level to represent color channels\n",
    "# because that's what convolutional layers expect.\n",
    "# \n",
    "# Dimensions:\n",
    "#   1. Number of images\n",
    "#   2. Rows\n",
    "#   3. Columns\n",
    "#   4. Pixel channels to represent color\n",
    "conv_x_train = x_train.reshape(len(x_train), 28, 28, 1)\n",
    "conv_x_test = x_test.reshape(len(x_test), 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 53s 28ms/step - loss: 0.4055 - accuracy: 0.8711 - val_loss: 0.0587 - val_accuracy: 0.9807\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 51s 27ms/step - loss: 0.1764 - accuracy: 0.9466 - val_loss: 0.0445 - val_accuracy: 0.9865\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 48s 26ms/step - loss: 0.1401 - accuracy: 0.9565 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 51s 27ms/step - loss: 0.1206 - accuracy: 0.9637 - val_loss: 0.0287 - val_accuracy: 0.9906\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 52s 28ms/step - loss: 0.1139 - accuracy: 0.9653 - val_loss: 0.0310 - val_accuracy: 0.9901\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 51s 27ms/step - loss: 0.1060 - accuracy: 0.9673 - val_loss: 0.0250 - val_accuracy: 0.9914\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 50s 27ms/step - loss: 0.0928 - accuracy: 0.9707 - val_loss: 0.0250 - val_accuracy: 0.9917\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 55s 29ms/step - loss: 0.0946 - accuracy: 0.9717 - val_loss: 0.0251 - val_accuracy: 0.9920\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 53s 28ms/step - loss: 0.0903 - accuracy: 0.9730 - val_loss: 0.0236 - val_accuracy: 0.9922\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 52s 28ms/step - loss: 0.0854 - accuracy: 0.9739 - val_loss: 0.0320 - val_accuracy: 0.9903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16f93cb80>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept = 'conv_with_aug'\n",
    "\n",
    "# Tensorboard\n",
    "log_fullfile = f'./tensorboard_logs/concept:{concept}'\n",
    "log_fullfile += '-Conv:32:3x3'\n",
    "log_fullfile += '-Max:2x2'\n",
    "log_fullfile += '-Dropout:0.25'\n",
    "log_fullfile += '-Conv:64:3x3'\n",
    "log_fullfile += '-Max:2x2'\n",
    "log_fullfile += '-Dropout:0.25'\n",
    "log_fullfile += '-Flatten'\n",
    "log_fullfile += '-Dense:64'\n",
    "log_fullfile += '-Dense:10'\n",
    "log_fullfile += f'-{time.time()}'\n",
    "tensorboard_callback = TensorBoard(log_dir=log_fullfile)\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.12,\n",
    "    width_shift_range=0.12,\n",
    "    height_shift_range=0.12\n",
    ")\n",
    "\n",
    "datagen.fit(conv_x_train)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPool2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    datagen.flow(\n",
    "        conv_x_train,\n",
    "        y_train,\n",
    "        batch_size=32  \n",
    "    ),\n",
    "    epochs=10,\n",
    "    validation_data=(conv_x_test, y_test),\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
